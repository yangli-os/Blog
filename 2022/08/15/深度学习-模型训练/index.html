<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Yang Li">
    
    <title>
        
            深度学习——模型训练篇 |
        
        YangLi&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"yangli-os.github.io","root":"/","language":"en","path":"search.xml"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066cc","avatar":"/images/饼干.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep Fighting."},"scroll":{"progress_bar":{"enable":false},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true,"trigger":"auto","unescape":false},"code_copy":{"enable":true,"style":"default"},"side_tools":{"enable":true},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                YangLi&#39;s Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">深度学习——模型训练篇</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/%E9%A5%BC%E5%B9%B2.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Yang Li</span>
                        
                            <span class="author-label">Lv1</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2022-08-15 21:12:00</span>
        <span class="mobile">2022-08-15 21:12</span>
    </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>这一章节主要介绍模型如何搭建起来的，以及模型上的一些训练方法。  </p>
<h1 id="1-模型搭建"><a href="#1-模型搭建" class="headerlink" title="1.模型搭建"></a>1.模型搭建</h1><h2 id="1-1-直接训练"><a href="#1-1-直接训练" class="headerlink" title="1.1 直接训练"></a>1.1 直接训练</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">loss_list = []</span><br><span class="line">acc_list = []</span><br><span class="line"></span><br><span class="line">class Network(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Network,self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=7,stride=2)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=256, out_channels=16, kernel_size=7,stride=2)</span><br><span class="line">        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5)</span><br><span class="line">        self.conv4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=[8,4])</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(in_features=16, out_features=16)</span><br><span class="line">        self.out = nn.Linear(in_features=16, out_features=2)</span><br><span class="line">    def forward(self, t):</span><br><span class="line">        #Layer 1</span><br><span class="line">        t = t</span><br><span class="line">        #Layer 2</span><br><span class="line">        t = self.conv1(t)</span><br><span class="line">        t = F.relu(t)</span><br><span class="line">        t = F.max_pool2d(t, kernel_size=2, stride=2)#output shape : (6,14,14)</span><br><span class="line">        #Layer 3</span><br><span class="line">        t = self.conv2(t)</span><br><span class="line">        t = F.relu(t)</span><br><span class="line">        t = F.max_pool2d(t, kernel_size=2, stride=2)#output shape : (6,14,14)</span><br><span class="line">        #Layer 4</span><br><span class="line">        t = self.conv3(t)</span><br><span class="line">        t = F.relu(t)</span><br><span class="line">        t = F.max_pool2d(t, kernel_size=2, stride=2)#output shape : (6,14,14)</span><br><span class="line">        #Layer 5      </span><br><span class="line">        t = self.conv4(t)</span><br><span class="line">        t = F.relu(t)</span><br><span class="line">        </span><br><span class="line">        #Layer 5</span><br><span class="line">        t=t.flatten(start_dim=1)</span><br><span class="line">        t = self.fc1(t)</span><br><span class="line">        t = F.relu(t)#output shape : (1,120)</span><br><span class="line">        #Layer 5</span><br><span class="line">        t = self.out(t)</span><br><span class="line"></span><br><span class="line">        return t</span><br><span class="line"></span><br><span class="line">network = Network()</span><br><span class="line"></span><br><span class="line">print(network)</span><br><span class="line">optimizer = optim.Adam(network.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)</span><br></pre></td></tr></table></figure>
<p>我batch_size的设置更改的比较多，再调整模型参数时主要调整了卷积的层数，神经元个数，卷积核的尺寸以及stride等。这里对参数需要注意的地方逐一记录一下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.Conv2d(in_channels=3, out_channels=256, kernel_size=7,stride=2)</span><br></pre></td></tr></table></figure>
<p>每一层的卷积都跟它上一层的输入输出有关，在第一层的卷积时，有几个参数需要注意。<br>in_channels： 为输入的维度，是图片的通道数<br>out_channels： 是自己可以随意设置的第一层卷积的输出<br>kernel_size： 是卷积核的尺寸<br>stride： 是卷积步长<br>卷积图片尺寸的计算为：<br>（W - kernel——size）/stride+1<br>因为我的图片较大，所以设置stride为2，可以快速的提取特征，经过池化后缩小尺寸。</p>
<p>注意：在此可以设置kernel_size为原始图像大小，但是输出的图片为X<em>X</em>1*1，就无法进行池化运算了。一般卷积核大小kernel_size设置为3，5，7为宜。</p>
<p>在卷积层之后，输入到线性层之前，使用了t.flatten(start_dim=1)，这里是因为卷积核输出后的数据格式是[x<em>x</em>1<em>1]，相当于是一个四维数据，输入linear的时候需要是[x</em>x]的形式，所以用了flatten展平，start_dim=1是不改变原有的尺寸。</p>
<p>还有一点，在输入linear的时候实际上与数据做的是矩阵运算，所以，对于[x<em>y]维度的数据，需要[y</em>x]的权重矩阵进行乘法运算才行。</p>
<h3 id="解决t-reshape-1-…-的问题"><a href="#解决t-reshape-1-…-的问题" class="headerlink" title="解决t.reshape(-1,…)的问题"></a>解决t.reshape(-1,…)的问题</h3><p>t.reshape(-1,…)中的第二个参数是t.size()除了第一个参数之外参数的乘积，也是接下来linear层的第一个输入。<br>所以想要省事可以写成</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line"></span><br><span class="line">mul_t = reduce(lambda x,y:x*y,list(t.size()))//batch_size</span><br><span class="line">t = t.reshape(-1,(mul_t)</span><br></pre></td></tr></table></figure>
<p>reshape后的数据input=mul_t的维度即可，output可以自行设置。</p>
<h2 id="1-2-Finetune模型微调"><a href="#1-2-Finetune模型微调" class="headerlink" title="1.2 Finetune模型微调"></a>1.2 Finetune模型微调</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 冻结模型参数的函数</span><br><span class="line">def set_parameter_requires_grad(model, feature_extracting):</span><br><span class="line">    if feature_extracting:</span><br><span class="line">        for param in model.parameters():</span><br><span class="line">            param.requires_grad = False</span><br><span class="line">            </span><br><span class="line"># 冻结参数的梯度</span><br><span class="line">feature_extract = True</span><br><span class="line"># pretrained=True 为使用原有的模型参数进行初始化训练，为False的话就只使用模型结构。</span><br><span class="line">model = models.resnet18(pretrained=True)</span><br><span class="line">set_parameter_requires_grad(model, feature_extract)</span><br><span class="line"></span><br><span class="line"># 修改模型</span><br><span class="line">num_ftrs = model.fc.in_features</span><br><span class="line">model.fc = nn.Linear(in_features=num_ftrs, out_features=128, bias=True)</span><br><span class="line">model.conv3 = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3,stride=2)</span><br><span class="line">model.bn3 = nn.BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">model.relu</span><br><span class="line">model.conv4 = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3,stride=2)</span><br></pre></td></tr></table></figure>
<h3 id="指修改部分层的参数"><a href="#指修改部分层的参数" class="headerlink" title="指修改部分层的参数"></a>指修改部分层的参数</h3><p>Fine-tune可以只保留部分层的参数，可是使用下面代码提取</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 去掉model的后5层</span><br><span class="line">self.resnet_layer = nn.Sequential(*list(model.children())[:-5])</span><br></pre></td></tr></table></figure>
<p>可以修改原始resnet模型当中的参数，使用resnet_layer[][]进行提取，print(network)的时候有一些会给出某一层或者某一sequence的标号。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.resnet_layer[0] = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3,stride=1)</span><br><span class="line">self.resnet_layer[1] = nn.BatchNorm2d(8)</span><br><span class="line">self.resnet_layer[4][0] = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3,stride=1)</span><br></pre></td></tr></table></figure>
<p>修改模型是可以修改已有的resnet18当中的模型结构和模型参数的，可以直接使用model.进行修改。<br>一般图像类的模型，修改后几层的参数，而一般语义类的模型，修改前几层的参数，这于模型训练时先后提取的特征有关</p>
<h1 id="2-自定义损失函数"><a href="#2-自定义损失函数" class="headerlink" title="2.自定义损失函数"></a>2.自定义损失函数</h1><p>针对样本不均衡的问题，使用focal_loss作为损失函数  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">class focal_loss(nn.Module):</span><br><span class="line">    def __init__(self, alpha=0.25, gamma=2, num_classes = 3, size_average=True):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        focal_loss损失函数, -α(1-yi)**γ *ce_loss(xi,yi)</span><br><span class="line">        步骤详细的实现了 focal_loss损失函数.</span><br><span class="line">        :param alpha:   阿尔法α,类别权重.      当α是列表时,为各类别权重,当α为常数时,类别权重为[α, 1-α, 1-α, ....],常用于 目标检测算法中抑制背景类 , retainnet中设置为0.25</span><br><span class="line">        :param gamma:   伽马γ,难易样本调节参数. retainnet中设置为2</span><br><span class="line">        :param num_classes:     类别数量</span><br><span class="line">        :param size_average:    损失计算方式,默认取均值</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        super(focal_loss,self).__init__()</span><br><span class="line">        self.size_average = size_average</span><br><span class="line">        if isinstance(alpha,list):</span><br><span class="line">            assert len(alpha)==num_classes   # α可以以list方式输入,size:[num_classes] 用于对不同类别精细地赋予权重</span><br><span class="line">            #print(&quot; --- Focal_loss alpha = &#123;&#125;, 将对每一类权重进行精细化赋值 --- &quot;.format(alpha))</span><br><span class="line">            self.alpha = torch.Tensor(alpha)</span><br><span class="line">        else:</span><br><span class="line">            assert alpha&lt;1   #如果α为一个常数,则降低第一类的影响,在目标检测中为第一类</span><br><span class="line">           #print(&quot; --- Focal_loss alpha = &#123;&#125; ,将对背景类进行衰减,请在目标检测任务中使用 --- &quot;.format(alpha))</span><br><span class="line">            self.alpha = torch.zeros(num_classes)</span><br><span class="line">            self.alpha[0] += alpha</span><br><span class="line">            self.alpha[1:] += (1-alpha) # α 最终为 [ α, 1-α, 1-α, 1-α, 1-α, ...] size:[num_classes]</span><br><span class="line"></span><br><span class="line">        self.gamma = gamma</span><br><span class="line"></span><br><span class="line">    def forward(self, preds, labels):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        focal_loss损失计算</span><br><span class="line">        :param preds:   预测类别. size:[B,N,C] or [B,C]    分别对应与检测与分类任务, B 批次, N检测框数, C类别数</span><br><span class="line">        :param labels:  实际类别. size:[B,N] or [B]</span><br><span class="line">        :return:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # assert preds.dim()==2 and labels.dim()==1</span><br><span class="line">        preds = preds.view(-1,preds.size(-1))</span><br><span class="line">        self.alpha = self.alpha.to(preds.device)</span><br><span class="line">        preds_logsoft = F.log_softmax(preds, dim=1) # log_softmax</span><br><span class="line">        preds_softmax = torch.exp(preds_logsoft)    # softmax</span><br><span class="line"></span><br><span class="line">        preds_softmax = preds_softmax.gather(1,labels.view(-1,1))   # 这部分实现nll_loss ( crossempty = log_softmax + nll )</span><br><span class="line">        preds_logsoft = preds_logsoft.gather(1,labels.view(-1,1))</span><br><span class="line">        self.alpha = self.alpha.gather(0,labels.view(-1))</span><br><span class="line">        loss = -torch.mul(torch.pow((1-preds_softmax), self.gamma), preds_logsoft)  # torch.pow((1-preds_softmax), self.gamma) 为focal loss中 (1-pt)**γ</span><br><span class="line"></span><br><span class="line">        loss = torch.mul(self.alpha, loss.t())</span><br><span class="line">        if self.size_average:</span><br><span class="line">            loss = loss.mean()</span><br><span class="line">        else:</span><br><span class="line">            loss = loss.sum()</span><br><span class="line">        return loss</span><br></pre></td></tr></table></figure>
<p>注意，想要使用focal_loss函数，在训练的时候loss不能是F.的形式，要进行修改。<br>原始格式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">preds = network(images)  # Pass batch</span><br><span class="line">loss = F.cross_entropy(preds, labels)  # Calculate Loss</span><br><span class="line"></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">loss.backward()  # Calculate gradients</span><br><span class="line">optimizer.step()  # Update weights</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>需要修改成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">preds = network(images)  # Pass batch</span><br><span class="line">criteria1 = nn.Cross_entropy()                # 这里不能用F.需要用nn.的形式</span><br><span class="line"># criterial = focal_loss                      # 替换损失函数</span><br><span class="line">loss = criteria1(preds, labels)</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">loss.backward()  # Calculate gradients</span><br><span class="line">optimizer.step()  # Update weights</span><br></pre></td></tr></table></figure>

<h1 id="3-实际训练"><a href="#3-实际训练" class="headerlink" title="3.实际训练"></a>3.实际训练</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">loss_list = []</span><br><span class="line">acc_list = []</span><br><span class="line"></span><br><span class="line">print(network)</span><br><span class="line">optimizer = optim.Adam(network.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)</span><br><span class="line">#schedule = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30,gamma=0.5)</span><br><span class="line"></span><br><span class="line">time_start = time.time()</span><br><span class="line">for epoch in range(epochs):</span><br><span class="line">    </span><br><span class="line">    total_correct = 0</span><br><span class="line">    total_loss = 0</span><br><span class="line">    for batch in train_loader:  # Get batch</span><br><span class="line">        images, labels = batch  # Unpack the batch into images and labels</span><br><span class="line"></span><br><span class="line">        preds = network(images)  # Pass batch</span><br><span class="line">        loss = F.cross_entropy(preds, labels)  # Calculate Loss</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()  # Calculate gradients</span><br><span class="line">        optimizer.step()  # Update weights</span><br><span class="line"></span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">        total_correct += preds.argmax(dim=1).eq(labels).sum().item()</span><br><span class="line">    loss_list.append(total_loss)</span><br><span class="line">    acc_list.append(total_correct/(len(train_loader)*batch_size))</span><br><span class="line">    print(&#x27;epoch:&#x27;, epoch, &quot;total_correct:&quot;, total_correct/(len(train_loader)*batch_size), &quot;loss:&quot;, total_loss)</span><br><span class="line">time_end = time.time() - time_start</span><br><span class="line">print(time_end)</span><br><span class="line">print(&#x27;&gt;&gt;&gt; Training Complete &gt;&gt;&gt;&#x27;)</span><br></pre></td></tr></table></figure>
<p>训练过程就是把数据放到我们已经搭建好的模型里面跑一下，这里需要注意的是损失函数的设置，将会影响分类的准确度。</p>
<p>这里的total_correct是整体准确的个数，用它除以总数就是准确率了。</p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：深度学习——模型训练篇</li>
        <li>Post author：Yang Li</li>
        <li>Create time：2022-08-15 21:12:00</li>
        <li>
            Post link：https://yangli-os.github.io//2022/08/15/深度学习-模型训练/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>&nbsp;
                    </li>
                
            </ul>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/08/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%95%B0%E6%8D%AE%E7%AF%87/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">深度学习——数据篇</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2022/08/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%AF%87/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">深度学习——模型评价篇</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            
    <div id="gitalk-container"></div>
    <script data-pjax
            src="//cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js"></script>
    <script data-pjax>

        function loadGitalk() {
            let __gitalk__pathname = decodeURI(location.pathname);
            const __gitalk__pathnameLength = __gitalk__pathname.length;
            const __gitalk__pathnameMaxLength = 50;
            if (__gitalk__pathnameLength > __gitalk__pathnameMaxLength) {
                __gitalk__pathname = __gitalk__pathname.substring(0, __gitalk__pathnameMaxLength - 3) + '...';
            }

            try {
                Gitalk && new Gitalk({
                    clientID: '838f65b43a27531a0d02',
                    clientSecret: 'fe71f678bf31af57c5eb0941809ab059e3b61f78',
                    repo: 'image-hosting',
                    owner: 'yangli-os',
                    admin: ['yangli-os'],
                    id: __gitalk__pathname,
                    language: 'en'
                }).render('gitalk-container');

            } catch (e) {
                window.Gitalk = null;
            }
        }

        if ('true') {
            const loadGitalkTimeout = setTimeout(() => {
                loadGitalk();
                clearTimeout(loadGitalkTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadGitalk);
        }
    </script>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Yang Li</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="nav-number">2.</span> <span class="nav-text">1.模型搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E7%9B%B4%E6%8E%A5%E8%AE%AD%E7%BB%83"><span class="nav-number">2.1.</span> <span class="nav-text">1.1 直接训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3t-reshape-1-%E2%80%A6-%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">2.1.1.</span> <span class="nav-text">解决t.reshape(-1,…)的问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-Finetune%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83"><span class="nav-number">2.2.</span> <span class="nav-text">1.2 Finetune模型微调</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%87%E4%BF%AE%E6%94%B9%E9%83%A8%E5%88%86%E5%B1%82%E7%9A%84%E5%8F%82%E6%95%B0"><span class="nav-number">2.2.1.</span> <span class="nav-text">指修改部分层的参数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.</span> <span class="nav-text">2.自定义损失函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E5%AE%9E%E9%99%85%E8%AE%AD%E7%BB%83"><span class="nav-number">4.</span> <span class="nav-text">3.实际训练</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/code-copy.js"></script>




<div class="post-scripts pjax">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/toc.js"></script>
    
</div>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
